# Cognitive Neuroscience

The goal of cognitive neuroscience is to relate cognitive processes and human behavior to neural processes. While this initially took the form of mapping cognitive processes to localized brain structures, this has given way to a network-distributed perspective: cognitive processes are supported by combinations of potentially anatomically distinct brain regions. For example, working memory relies on frontal, parietal, and modality specific regions working in tandem, and self-referential thinking taps the default mode network. Even within a single region, the relationship between brain activity and behavior can be complex. Stimuli from a wide range of stimulus domains can be decoded from the same patch of cortex in the ventral temporal lobe, for example. What differentiates the neurocognitive representations of “shoe” and “chair”, for example, is not where the brain is active, but the specific pattern of activation. Furthermore, the neurocognitive representation of a stimulus, concept, or process may not be anatomically contiguous, and some neural units that contribute to the representation may contribute more than others. Identifying relationships between the brain and behavior is thus a serious challenge.

## Using Machine Learning 

In attempts to overcome this challenge, many cognitive neuroscientists have begun to experiment with techniques developed for machine learning, including regularized regression, support vector machines, and deep neural networks, to learn models that aim to decode patterns of neural activity into the condition or stimulus labels that they are associated with. Machine learning is not magic, however. To learn an accurate model requires a large number of labeled stimuli or conditions; ideally, there would be more labeled examples than there are neural features, but this is very rarely the case in cognitive neuroscience where it is typical to model each subject individually.

Ideally, this could be combated by combining the data from multiple subjects in the same data. The simplest strategy involves anatomically aligning all subjects to the same template and concatenating all the functional data by trial. This is similar to what is done in some univariate analyses of fMRI data, but it’s not ideal for multivariate decoding studies. To do so would assume that voxels at the same standard-space coordinate across subjects share a common response profile, and this is known to not be the case. Before aggregating across subjects–or even potentially across studies–the datasets should be functionally aligned, such that all datasets are described with respect to the same functional features.

## Domain Adaptation

Again, we can borrow from the machine learning literature to attempt to achieve this goal. In what follows, I will introduce a computational technique called domain adaptation which has already proved promising for aligning fMRI datasets from multiple subjects, collected across multiple sites and scanners, and even across studies, to effectively increase the training set used for machine learning. When target and source domains share key elements of functional variance relevant to the machine learning classification problem, regardless of how that functional variance is expressed in the voxel-space of each subject, model fits can improve. I will begin with an overview of machine learning before explaining what domain adaptation is, how it can be used in cognitive neuroscience, and when and why it can be applied.